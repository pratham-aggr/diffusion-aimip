apiVersion: batch/v1
kind: Job
metadata:
  name: ${JOB_NAME}
  namespace: climate-analytics
spec:
  ttlSecondsAfterFinished: 86400
  template:
    spec:
      restartPolicy: Never
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
        runAsGroup: 1000
      volumes:
        - name: workspace
          emptyDir: {}
        - name: wandb-cache
          emptyDir: {}
        - name: cb-results
          persistentVolumeClaim:
            claimName: cb-daily-checkpoints
        - name: weatherbench
          persistentVolumeClaim:
            claimName: weatherbench
      containers:
        - name: climatebench-edm
          image: python:3.10
          imagePullPolicy: IfNotPresent
          workingDir: /workspace
          env:
            - name: WANDB_API_KEY
              valueFrom:
                secretKeyRef:
                  name: ${WANDB_SECRET_NAME}
                  key: api-key
            - name: RUN_NAME
              value: ${JOB_NAME}
            - name: RUN_ID
              value: ${JOB_NAME}
            - name: DATA_DIR
              value: gs://weatherbench2/datasets/era5/1959-2022-6h-240x121_equiangular_with_poles_conservative.zarr
            - name: STATS_DIR
              value: /workspace/era5_statistics
            - name: WANDB_DIR
              value: /wandb
            - name: WANDB_CONFIG_DIR
              value: /wandb
            - name: WANDB_CACHE_DIR
              value: /wandb
            - name: WANDB_DATA_DIR
              value: /wandb
            - name: HYDRA_FULL_ERROR
              value: "1"
            - name: TORCH_CUDNN_V8_API_ENABLED
              value: "1"
          command: ["/bin/bash", "-c"]
          args:
            - |
              set -euo pipefail
              mkdir -p /workspace
              cd /workspace
              
              # Always clone fresh from GitHub to ensure latest changes
              echo "Cloning repository from GitHub..."
              rm -rf climatebench
              git clone --depth=1 https://github.com/pratham-aggr/diffusion-aimip.git climatebench
              cd climatebench
              
              # Ensure we're on main and have latest
              git checkout main || true
              git pull origin main || true
                            
              # Verify repository and key files
              echo "Repository cloned. Current branch:"
              git branch
              echo "Latest commit:"
              git log -1 --oneline
              echo "Verifying key files exist..."
              echo "Contents of src/configs/experiments/:"
              ls -la src/configs/experiments/ 2>/dev/null || echo "Directory does not exist"
              if [ ! -f "src/configs/experiments/example.yaml" ]; then
                echo "ERROR: example.yaml not found in repository!"
                exit 1
              fi
              if [ ! -f "src/configs/experiments/era5_sst_seaice_emulation_edm_aimip_tuned_v2.yaml" ]; then
                echo "ERROR: era5_sst_seaice_emulation_edm_aimip_tuned_v2.yaml not found in repository!"
                exit 1
              fi
              echo "✓ All required experiment configs found"
              # Patch wandb error handling: fix wandb.errors.errors.Error to wandb.errors.Error
              python -c "c=open('src/experiment_types/_base_experiment.py').read(); c=c.replace('except wandb.errors.errors.Error as e:', 'except wandb.errors.Error as e:'); open('src/experiment_types/_base_experiment.py','w').write(c); print('Patched wandb.errors.errors.Error')" || true
              # Install packages - ensure HOME is set for user installs
              export HOME=/tmp/home
              mkdir -p "$HOME"
              python -m pip install --upgrade pip --user
              if [ -f requirements.txt ]; then
                pip install --no-cache-dir --user -r requirements.txt
              fi
              pip install --no-cache-dir --user cartopy boto3 xbatcher "dask[distributed]" gcsfs seaborn
              pip install --no-cache-dir --user -e .[train]
              # Add user site-packages to PYTHONPATH
              export PYTHONPATH="${HOME}/.local/lib/python3.10/site-packages:${PYTHONPATH:-}"
              ERA5_STATS_DIR="${STATS_DIR:-/workspace/era5_statistics}"
              if [ -z "$ERA5_STATS_DIR" ]; then
                ERA5_STATS_DIR="/workspace/era5_statistics"
              fi
              mkdir -p "$ERA5_STATS_DIR"
              # Use exact GCS dataset path (public bucket, no credentials needed)
              echo "Using GCS dataset: ${DATA_DIR}"
              echo "Verifying GCS dataset access (public bucket)..."
              python -c "import gcsfs; fs = gcsfs.GCSFileSystem(); exists = fs.exists('${DATA_DIR}'); print(f'GCS dataset accessible: {exists}'); exit(0 if exists else 1)" || {
                echo "ERROR: GCS dataset not accessible: ${DATA_DIR}"
                exit 1
              }
              echo "GCS dataset verified: ${DATA_DIR}"
              # Setup results directory with proper permissions first
              RESULTS_DIR_BASE=/results
              mkdir -p "$RESULTS_DIR_BASE" || true
              chmod -R 777 "$RESULTS_DIR_BASE" || true
              # Check for statistics in weatherbench PVC (required)
              PERSISTENT_STATS_DIR=/weatherbench/era5_statistics
              echo "Checking for statistics in PVC: $PERSISTENT_STATS_DIR"
              
              if [ ! -f "$PERSISTENT_STATS_DIR/era5_mean.nc" ] || [ ! -f "$PERSISTENT_STATS_DIR/era5_std.nc" ]; then
                echo "ERROR: Statistics files not found in PVC!"
                echo "Expected files:"
                echo "  - $PERSISTENT_STATS_DIR/era5_mean.nc"
                echo "  - $PERSISTENT_STATS_DIR/era5_std.nc"
                echo ""
                echo "Please upload statistics to the weatherbench PVC first using:"
                echo "  bash scripts/k8s/upload-stats.sh"
                echo ""
                echo "Contents of $PERSISTENT_STATS_DIR:"
                ls -la "$PERSISTENT_STATS_DIR" 2>&1 || echo "Directory does not exist"
                exit 1
              fi
              
              echo "✓ Found statistics in PVC: $PERSISTENT_STATS_DIR"
              echo "Files:"
              ls -lh "$PERSISTENT_STATS_DIR"/*.nc
              
              # Copy statistics to workspace for training
              mkdir -p "$ERA5_STATS_DIR"
              cp "$PERSISTENT_STATS_DIR/era5_mean.nc" "$ERA5_STATS_DIR/"
              cp "$PERSISTENT_STATS_DIR/era5_std.nc" "$ERA5_STATS_DIR/"
              echo "Copied statistics to $ERA5_STATS_DIR"
              RESULTS_DIR=$RESULTS_DIR_BASE/${RUN_ID}
              if ! mkdir -p "$RESULTS_DIR/logs"; then
                echo "WARNING: Unable to write to $RESULTS_DIR_BASE. Falling back to /workspace/results."
                RESULTS_DIR_BASE=/workspace/results
                RESULTS_DIR=$RESULTS_DIR_BASE/${RUN_ID}
                mkdir -p "$RESULTS_DIR/logs"
              fi
              # Ensure we're in the climatebench directory
              if [ ! -f "run.py" ]; then
                echo "ERROR: run.py not found. Current directory: $(pwd)"
                echo "Contents of current directory:"
                ls -la
                exit 1
              fi
              echo "Running training from directory: $(pwd)"
              python run.py \
                experiment=era5_sst_seaice_emulation_edm_aimip_tuned_v2 \
                trainer.accelerator="gpu" \
                trainer.devices=2 \
                work_dir=$RESULTS_DIR \
                ckpt_dir=$RESULTS_DIR/checkpoints \
                log_dir=$RESULTS_DIR/logs \
                datamodule.data_dir=${DATA_DIR} \
                datamodule.batch_size=64 \
                datamodule.batch_size_per_gpu=16 \
                datamodule.data_dir_stats=${STATS_DIR} \
                +module.pr_clamping=false \
                logger.wandb.project="ERA5-Climate-Emulation" \
                logger.wandb.entity="climate-analytics-lab" \
                logger.wandb.save_to_wandb=true \
                logger.wandb.save_to_s3_bucket=false \
                ++logger.wandb.mode="online"
          resources:
            requests:
              nvidia.com/gpu: 2
              cpu: "8"
              memory: "40Gi"
            limits:
              nvidia.com/gpu: 2
              cpu: "9.6"
              memory: "48Gi"
          volumeMounts:
            - name: workspace
              mountPath: /workspace
            - name: wandb-cache
              mountPath: /wandb
            - name: cb-results
              mountPath: /results
            - name: weatherbench
              mountPath: /weatherbench

